import streamlit as st
import requests
import json

# --- Configuraci칩n de la P치gina ---
st.set_page_config(page_title="Coomeva Seguros - Asistente Virtual Interno", layout="wide")

# --- T칤tulo y Descripci칩n ---
st.title("游뱄 Asistente Virtual Interno de Coomeva Seguros")
st.caption("Este asistente te ayudar치 a responder preguntas sobre productos, servicios y procedimientos internos de Coomeva Seguros.")

# --- URL del Backend FastAPI ---
# Aseg칰rate de que tu backend FastAPI (main.py) est칠 ejecut치ndose.
# Si ejecutas Streamlit y FastAPI en la misma m치quina, esta URL deber칤a funcionar.
# Si est치n en diferentes m치quinas o contenedores, ajusta la URL.
FASTAPI_URL = "http://localhost:8000/v1/chat/completions"

# --- Inicializar el estado de la sesi칩n para el historial del chat ---
if "messages" not in st.session_state:
    st.session_state.messages = [
        {"role": "assistant", "content": "Hola, soy tu asistente virtual de Coomeva Seguros. 쮼n qu칠 puedo ayudarte hoy?"}
    ]

# --- Mostrar mensajes del chat ---
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# --- Entrada del Usuario ---
if prompt := st.chat_input("Escribe tu pregunta aqu칤..."):
    # A침adir mensaje del usuario al historial y mostrarlo
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # Preparar el payload para el backend
    # El backend espera una lista de mensajes, siendo el 칰ltimo el del usuario.
    # Para simplificar, aqu칤 solo enviamos el mensaje actual del usuario
    # en el formato que espera el backend.
    # Si tuvieras un historial m치s complejo o un formato de payload diferente, aj칰stalo.
    payload = {
        "messages": [{"role": "user", "content": prompt}]
        # Puedes a침adir otros par치metros que tu API espere, como 'model', 'stream', etc.
        # "model": "qwen" # Ejemplo si necesitaras especificar el modelo
    }

    # Llamar al backend FastAPI
    try:
        with st.spinner("Pensando..."):
            response = requests.post(FASTAPI_URL, json=payload, timeout=180) # Timeout de 3 minutos
            response.raise_for_status()  # Lanza una excepci칩n para errores HTTP (4xx o 5xx)
            
            response_data = response.json()
            
            # Extraer la respuesta del asistente del JSON
            # Esto asume que tu backend devuelve un JSON con la estructura OpenAI
            assistant_reply = response_data.get("choices", [{}])[0].get("message", {}).get("content", "")
            
            if not assistant_reply:
                assistant_reply = "No he podido obtener una respuesta clara del backend."

    except requests.exceptions.RequestException as e:
        assistant_reply = f"Error al conectar con el backend: {e}"
        st.error(assistant_reply)
    except json.JSONDecodeError:
        assistant_reply = "Error al decodificar la respuesta del backend. 쮼st치 el backend devolviendo un JSON v치lido?"
        st.error(assistant_reply)
    except Exception as e:
        assistant_reply = f"Ha ocurrido un error inesperado: {e}"
        st.error(assistant_reply)

    # A침adir respuesta del asistente al historial y mostrarla
    st.session_state.messages.append({"role": "assistant", "content": assistant_reply})
    with st.chat_message("assistant"):
        st.markdown(assistant_reply)

# --- Barra lateral (Opcional) ---
st.sidebar.header("Acerca de")
st.sidebar.info(
    "Este es un asistente virtual para funcionarios de Coomeva Seguros. "
    "Utiliza un modelo de lenguaje avanzado y recuperaci칩n de informaci칩n para responder tus preguntas."
)
st.sidebar.markdown("---")
st.sidebar.markdown("Desarrollado con Streamlit y FastAPI.") 